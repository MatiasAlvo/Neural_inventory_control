{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch import nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import everything in neural_networks.ipynb (considering it is a notebook)\n",
    "from ipynb.fs.full.neural_networks import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Class that will represent our sampled data. As it inherits from Dataset (torch module), we need to define __ len __ (defines number of samples) and __ getitem __ (defines how to \"get\" a sample) methods. A Dataset object is then passed to a DataLoader one, which handles loading the data (including possible shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemandDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for demand data\n",
    "    \"\"\"\n",
    "    def __init__(self, demand_parameters, problem_params, data_params, seed=None):\n",
    "        \"\"\"\n",
    "        demand_parameters: dict, parameters for demand data\n",
    "        problem_params: dict, parameters for the problem\n",
    "        data_params: dict, parameters for the data\n",
    "        seed: int, seed for random number generator\n",
    "        \"\"\"\n",
    "\n",
    "        self.demand_parameters = demand_parameters\n",
    "        self.problem_params = problem_params\n",
    "        self.data_params = data_params\n",
    "        self.periods = self.problem_params['periods']\n",
    "        self.num_samples = self.data_params['num_samples']\n",
    "        self.seed = seed\n",
    "\n",
    "        demand_generator_functions = {\"normal\": self.generate_normal_demand_for_one_store}\n",
    "\n",
    "        self.data = demand_generator_functions[demand_parameters['distribution']](demand_parameters)\n",
    "    \n",
    "    \n",
    "    def generate_normal_demand_for_one_store(self, demand_parameters, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate normal demand data for one store\n",
    "        \"\"\"\n",
    "\n",
    "        # set seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        # generate normal distribution, and truncate at 0 from below\n",
    "        data = np.random.normal(demand_parameters['mean'], \n",
    "                                demand_parameters['std'], \n",
    "                                size=(self.num_samples, 1, self.periods)\n",
    "                                )\n",
    "        # print(data.shape)\n",
    "\n",
    "        return data\n",
    "        \n",
    "\n",
    "    def generate_data(self, demand_parameters, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate demand data\n",
    "        \"\"\"\n",
    "        demand_generator_functions = {\"normal\": self.generate_normal_demand_for_one_store}\n",
    "        demand = demand_generator_functions[demand_parameters['distribution']](demand_parameters, **kwargs)\n",
    "        \n",
    "        if kwargs['clip']:\n",
    "            data = np.clip(data, 0, None)\n",
    "\n",
    "        return \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FullyConnectedNN(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Fully connected neural network\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, neurons_per_hidden_layer, output_size):\n",
    "#         \"\"\"\n",
    "#         Arguments:\n",
    "#             neurons_per_hidden_layer: list\n",
    "#                 list of integers, where each integer is the number of neurons in a hidden layer\n",
    "#         \"\"\"\n",
    "\n",
    "#         super().__init__() # initialize super class\n",
    "\n",
    "#         # define layers\n",
    "#         self.activation_function = nn.ELU()\n",
    "#         self.layers = []\n",
    "#         for output_neurons in neurons_per_hidden_layer:\n",
    "#             self.layers.append(nn.LazyLinear(output_neurons))\n",
    "#             self.layers.append(self.activation_function)\n",
    "#         self.layers.append(nn.LazyLinear(output_size))\n",
    "        \n",
    "#         # define network as a sequence of layers\n",
    "#         self.net = nn.Sequential(*self.layers)\n",
    "    \n",
    "#     def forward(self, state):\n",
    "#         \"\"\"\n",
    "#         Forward pass\n",
    "#         \"\"\"\n",
    "#         x = state['x']\n",
    "#         # flatten input, except for the batch dimension\n",
    "#         # x = x.view(x.size(0), -1)\n",
    "#         x = x.flatten(start_dim=1)\n",
    "#         # print(f'x.device: {x.device}')\n",
    "#         # print(f'x.shape: {x.shape}')\n",
    "#         # add 1.0 to the output of the network to ensure that the output is positive at initialization\n",
    "#         # otherwise, when applying the clip operator (equivalently, the positive part operator), we won't 'get a gradient'\n",
    "#         # x = self.net(x)[:, 0] + 1.0\n",
    "#         x = self.net(x) + 1.0\n",
    "\n",
    "#         return torch.clip(x, min=0) # clip output to be non-negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateHandler():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform_state_to_input(self, state):\n",
    "        \"\"\"\n",
    "        Transform state to input for the neural network\n",
    "        \"\"\"\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator class\n",
    "Object that represents the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(nn.Module):\n",
    "    \"\"\"\n",
    "    Simulator class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, parameters, device='cpu'):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            parameters: dict\n",
    "                dictionary containing the parameters of the environment\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__() # initialize super class\n",
    "        \n",
    "        self.device = device\n",
    "        self.parameters = parameters\n",
    "        self.periods = parameters['periods']\n",
    "        self.underage_cost = torch.tensor(parameters['underage_cost'])\n",
    "        self.holding_cost = torch.tensor(parameters['holding_cost'])\n",
    "        self.lead_time = parameters['lead_time']\n",
    "        self.lost_demand = parameters['lost_demand']\n",
    "    \n",
    "    def move_columns_left(self, tensor_to_displace, start_index, end_index):\n",
    "        \"\"\"\n",
    "        move all columns in given array to the left, and return as list\n",
    "        \"\"\"\n",
    "\n",
    "        return [tensor_to_displace[:, :, i + 1] for i in range(start_index, end_index)]\n",
    "        # return [tensor_to_displace[:, i + 1] for i in range(start_index, end_index)]\n",
    "\n",
    "    \n",
    "    def update_state(self, state, action, demand):\n",
    "        \"\"\"\n",
    "        Update the state of the environment\n",
    "        \"\"\"\n",
    "        inventory_on_hand = state[:, :,  0] - demand\n",
    "        if self.lost_demand:\n",
    "            inventory_on_hand = torch.clip(inventory_on_hand, min=0)\n",
    "        \n",
    "\n",
    "        # print(f'inventory on hand: {inventory_on_hand.shape}')\n",
    "        # print(f'state: {state.shape}')\n",
    "        # print(f'self.move_columns_left(state, 1, self.lead_time - 1).shape: {self.move_columns_left(state, 1, self.lead_time - 1)[0].shape}')\n",
    "        # print(f'action: {action.shape}')\n",
    "        # print()\n",
    "        \n",
    "        return torch.stack([inventory_on_hand + state[:, :, 1],\n",
    "                            *self.move_columns_left(state, 1, self.lead_time - 1),\n",
    "                            action],\n",
    "                            dim=2\n",
    "                            )\n",
    "\n",
    "    # def update_state(self, state, action, demand):\n",
    "    #     \"\"\"\n",
    "    #     Update the state of the environment\n",
    "    #     \"\"\"\n",
    "    #     inventory_on_hand = state[:, 0] - demand\n",
    "    #     if self.lost_demand:\n",
    "    #         inventory_on_hand = torch.clip(inventory_on_hand, min=0)\n",
    "        \n",
    "    #     return torch.stack([inventory_on_hand + state[:, 1],\n",
    "    #                         *self.move_columns_left(state, 1, self.lead_time - 1),\n",
    "    #                         action],\n",
    "    #                         dim=1\n",
    "    #                         )\n",
    "    \n",
    "    # def update_inventory_for_long_lead_time(self, inventory_on_hand, inventory, lead_time, allocation):\n",
    "\n",
    "    #     return torch.stack([inventory_on_hand + inventory[:, :, 1],\n",
    "    #                         *self.move_columns_left(inventory, 1, lead_time - 1),\n",
    "    #                         allocation],\n",
    "    #                        dim=2)\n",
    "    \n",
    "    def step(self, state, action, demand):\n",
    "        \"\"\"\n",
    "        Simulate one step in the environment\n",
    "        \"\"\"\n",
    "        # get inventory on hand (i.e., at the store before demand arrives)\n",
    "        inventory_on_hand = state[:, :, 0]\n",
    "        # print(f'self.underage_cost: {self.underage_cost.device}')\n",
    "        # print(f'self.holding_cost: {self.holding_cost.device}')\n",
    "        # print(f'inventory_on_hand: {inventory_on_hand.device}')\n",
    "        # print(f'demand: {demand.device}')\n",
    "        # calculate reward as sum of underage and holding costs\n",
    "        reward = self.underage_cost * torch.clip(demand - inventory_on_hand, min=0).sum() + self.holding_cost * torch.clip(inventory_on_hand - demand, min=0).sum()\n",
    "        # update state\n",
    "        state = self.update_state(state, action, demand)\n",
    "        # return state and reward\n",
    "        return state, reward\n",
    "    \n",
    "    def simulate_batch(self, model, demand_batch):\n",
    "        \"\"\"\n",
    "        Simulate a batch of demand data\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize state as a matrix of zeros\n",
    "        state = torch.zeros(demand_batch.shape[0], demand_batch.shape[1], self.lead_time).to(self.device)\n",
    "        # print(f'initial state: {state.shape}')\n",
    "        # initialize reward across batch\n",
    "        batch_reward = 0\n",
    "        reward_to_report = 0\n",
    "\n",
    "        # loop through periods\n",
    "        for period in range(self.periods):\n",
    "            # get demand\n",
    "            demand = demand_batch[:, :, period]\n",
    "            # get action (i.e, order quantity)\n",
    "            action = model({'x': state})\n",
    "            # action = model(state)\n",
    "            # print(f'state: {state[0]}')\n",
    "            # print(f'action: {action[0]}')\n",
    "            # print(f'demand: {demand[0]}')\n",
    "            # print()\n",
    "            # get new state and reward\n",
    "            state, reward = self.step(state, action, demand)\n",
    "            \n",
    "\n",
    "            batch_reward += reward\n",
    "            # add reward to batch reward only after lead time has passed (as costs on first periods do not depend on agent's actions)\n",
    "            if period >= 20:\n",
    "            # if period >= self.lead_time:\n",
    "                reward_to_report += reward\n",
    "\n",
    "        # return reward\n",
    "        return batch_reward, reward_to_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer class\n",
    "Object that trains the model (i.e., Neural Net) making use of the data, optimizer (this object updates the parameters of the NN), and simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\"\n",
    "    Trainer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device='cpu'):\n",
    "        \n",
    "        self.all_train_losses = []\n",
    "        self.all_test_losses = [] \n",
    "        self.device = device\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the losses\n",
    "        \"\"\"\n",
    "\n",
    "        self.all_train_losses = []\n",
    "        self.all_test_losses = []\n",
    "\n",
    "    def train(self, epochs, model, train_loader, test_loader, optimizer, simulator):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        \n",
    "        # number of periods for which we are tracking the loss\n",
    "        periods_tracking_loss = 30\n",
    "        # periods_tracking_loss = simulator.parameters['periods'] - simulator.parameters['lead_time']\n",
    "\n",
    "        for epoch in range(epochs): # make multiple passes through the dataset\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_loss_to_report = 0.0\n",
    "            test_loss_to_report = 0.0\n",
    "            total_train_samples = 0\n",
    "            total_test_samples = 0\n",
    "\n",
    "            for i, demand_batch in enumerate(train_loader, 0):  # loop through batches of train data\n",
    "                # move data to device\n",
    "                demand_batch = demand_batch.to(self.device)\n",
    "\n",
    "                # zero-out the gradient\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward pass\n",
    "                total_reward, reward_to_report = simulator.simulate_batch(model, demand_batch.float())\n",
    "                epoch_loss += total_reward.item()\n",
    "                epoch_loss_to_report += reward_to_report.item()\n",
    "                total_train_samples += len(demand_batch)\n",
    "                loss = total_reward/(len(demand_batch)*(demand_batch.shape[2]))\n",
    "                # loss_to_report = total_reward/(len(demand_batch))\n",
    "\n",
    "                # backward pass (to calculate gradient) and take gradient step\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            for i, demand_batch in enumerate(test_loader, 0):  # loop through batches of test data\n",
    "                demand_batch = demand_batch.to(self.device)\n",
    "                # forward pass\n",
    "                total_reward, reward_to_report = simulator.simulate_batch(model, demand_batch.float())\n",
    "                test_loss_to_report += reward_to_report.item()\n",
    "                # test_loss += simulator.simulate_batch(model, demand_batch.float()).item()\n",
    "                total_test_samples += len(demand_batch)\n",
    "\n",
    "            average_train_loss = epoch_loss_to_report/(total_train_samples*periods_tracking_loss)\n",
    "            average_test_loss = test_loss_to_report/(total_test_samples*periods_tracking_loss)\n",
    "\n",
    "            self.all_train_losses.append(average_train_loss)\n",
    "            self.all_test_losses.append(average_test_loss)\n",
    "\n",
    "            # print epoch number and average per-period loss every 10 epochs\n",
    "            if epoch % 10 == 9:\n",
    "                print()\n",
    "                print(f'epoch: {epoch + 1}')\n",
    "                print(f'Average per-period train loss: {average_train_loss}')\n",
    "                print(f'Average per-period test loss: {average_test_loss}')\n",
    "            # print(f'test loss: {test_loss/(test_samples*(parameters[\"periods\"] - parameters[\"lead_time\"]))}')\n",
    "            epoch_loss = 0.0\n",
    "    \n",
    "    def plot_losses(self, ymin=None, ymax=None):\n",
    "        \"\"\"\n",
    "        Plot train and test losses for each epoch\n",
    "        \"\"\"\n",
    "\n",
    "        plt.plot(self.all_train_losses, label='train loss')\n",
    "        plt.plot(self.all_test_losses, label='test loss')\n",
    "        plt.legend()\n",
    "\n",
    "        if ymin is not None and ymax is not None:\n",
    "            plt.ylim(ymin, ymax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter definition and object instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_parameters = {'distribution': 'normal', 'mean': 5, 'std': 1.6} # mean and standard deviation of normal demand\n",
    "train_seed = 42\n",
    "test_seed = 43\n",
    "periods = 50\n",
    "train_samples = 2**13\n",
    "test_samples = 2**13\n",
    "data_params_train = {'num_samples': train_samples}\n",
    "data_params_test = {'num_samples': test_samples}\n",
    "problem_params = {'periods': periods, 'lost_demand': False}\n",
    "store_params = {'lead_time': 4, 'underage_cost': 1, 'holding_cost': 0.5}\n",
    "# demand_parameters, problem_params, data_params, seed=None\n",
    "# create a DemandDataset object with specific mean, std, seeds, periods, and samples for train and test sets\n",
    "train_demand_dataset = DemandDataset(demand_parameters, problem_params, data_params_train, train_seed)\n",
    "test_demand_dataset = DemandDataset(demand_parameters, problem_params, data_params_test, test_seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "print(train_demand_dataset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 2**10\n",
    "test_batch_size = 2**10\n",
    "\n",
    "# create DataLoader objects\n",
    "train_loader = DataLoader(train_demand_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_demand_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m simulator \u001b[38;5;241m=\u001b[39m Simulator(\u001b[43mparameters\u001b[49m, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "simulator = Simulator(parameters, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/ma4177/.conda/envs/MatiasRL/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "parameters = {'periods': 50, \n",
    "              'initial_inventory': 0.0, \n",
    "              'underage_cost': 9.0, \n",
    "              'holding_cost': 1.0, \n",
    "              'lead_time': 4, \n",
    "              'stores': 1,\n",
    "              'warehouses': 0,\n",
    "              'lost_demand': False}\n",
    "\n",
    "neurons_per_hidden_layer = [32, 32, 32]\n",
    "lr = 0.003\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create a simulator object with the following parameters\n",
    "simulator = Simulator(parameters, device=device).to(device)\n",
    "# create a fully connected neural network with LazyLinear layers (i.e., input size is inferred from data) and Tanh activation function\n",
    "model = FullyConnectedNN(neurons_per_hidden_layer, output_size=parameters['stores']).to(device)\n",
    "# create an Adam optimizer with specified learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# create a trainer\n",
    "trainer = Trainer(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10\n",
      "Average per-period train loss: 6.329889043172201\n",
      "Average per-period test loss: 6.2838900248209635\n",
      "\n",
      "epoch: 20\n",
      "Average per-period train loss: 6.30523370107015\n",
      "Average per-period test loss: 6.259692192077637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# train the model for many epochs\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs, model, train_loader, test_loader, optimizer, simulator)\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m total_reward, reward_to_report \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemand_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_reward\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     47\u001b[0m epoch_loss_to_report \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward_to_report\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[5], line 115\u001b[0m, in \u001b[0;36mSimulator.simulate_batch\u001b[0;34m(self, model, demand_batch)\u001b[0m\n\u001b[1;32m    108\u001b[0m action \u001b[38;5;241m=\u001b[39m model({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: state})\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# action = model(state)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# print(f'state: {state[0]}')\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# print(f'action: {action[0]}')\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# print(f'demand: {demand[0]}')\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# get new state and reward\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m state, reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m batch_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# add reward to batch reward only after lead time has passed (as costs on first periods do not depend on agent's actions)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 85\u001b[0m, in \u001b[0;36mSimulator.step\u001b[0;34m(self, state, action, demand)\u001b[0m\n\u001b[1;32m     79\u001b[0m inventory_on_hand \u001b[38;5;241m=\u001b[39m state[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# print(f'self.underage_cost: {self.underage_cost.device}')\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# print(f'self.holding_cost: {self.holding_cost.device}')\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# print(f'inventory_on_hand: {inventory_on_hand.device}')\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print(f'demand: {demand.device}')\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# calculate reward as sum of underage and holding costs\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munderage_cost \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minventory_on_hand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholding_cost \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mclip(inventory_on_hand \u001b[38;5;241m-\u001b[39m demand, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# update state\u001b[39;00m\n\u001b[1;32m     87\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_state(state, action, demand)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trainer.lr = 0.1\n",
    "# You can run this cell multiple times, and the training will be resumed from the previous state (unless you re-run the cell that instantiates the Neural Net)\n",
    "epochs = 1000\n",
    "# train the model for many epochs\n",
    "trainer.train(epochs, model, train_loader, test_loader, optimizer, simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "ymin, ymax = 0, 100  # set the y-axis limit for the plot\n",
    "trainer.plot_losses(ymin=ymin, ymax=ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

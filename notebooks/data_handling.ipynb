{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.shared_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scenario():\n",
    "    '''\n",
    "    Class to generate a setting when there are parameters to be sampled.\n",
    "    For example, we might sample the mean demand and std for each store, which is later going to be used to sample actual demand samples\n",
    "    '''\n",
    "    def __init__(self, periods, problem_params, store_params, warehouse_params, num_samples, seeds=None):\n",
    "\n",
    "        self.problem_params = problem_params\n",
    "        self.store_params = store_params\n",
    "        self.warehouse_params = warehouse_params\n",
    "        self.num_samples = num_samples\n",
    "        self.periods = periods\n",
    "        self.seeds = seeds\n",
    "\n",
    "        self.demands = self.generate_demand_samples(problem_params, store_params['demand'], seeds)\n",
    "        self.underage_costs = self.generate_data_for_samples_and_stores(problem_params, store_params['underage_cost'], seeds['underage_cost'], discrete=False)\n",
    "        self.holding_costs = self.generate_data_for_samples_and_stores(problem_params, store_params['holding_cost'], seeds['holding_cost'], discrete=False)\n",
    "        self.lead_times = self.generate_data_for_samples_and_stores(problem_params, store_params['lead_time'], seeds['lead_time'], discrete=True)\n",
    "        self.initial_inventories = self.generate_initial_inventories(problem_params, store_params, self.demands, seeds['initial_inventory'])\n",
    "        self.initial_warehouse_inventories = self.generate_initial_warehouse_inventory(warehouse_params)\n",
    "\n",
    "        self.days_from_christmas = self.generate_days_from_christmas(store_params)\n",
    "        self.split_by = self.define_how_to_split_data()\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Return the generated data. Will be part of a Dataset\n",
    "        \"\"\"\n",
    "\n",
    "        data =  {'demands': self.demands,\n",
    "                'underage_costs': self.underage_costs,\n",
    "                'holding_costs': self.holding_costs,\n",
    "                'lead_times': self.lead_times,\n",
    "                'initial_inventories': self.initial_inventories,\n",
    "                'initial_warehouse_inventories': self.initial_warehouse_inventories,\n",
    "                'days_from_christmas': self.days_from_christmas\n",
    "                }\n",
    "        \n",
    "        return {k: v.float() for k, v in data.items() if v is not None}\n",
    "    \n",
    "    def define_how_to_split_data(self):\n",
    "        \"\"\"\n",
    "        Define how to split the data into different samples\n",
    "        If demand comes from real data, the training and dev sets correspond to different periods.\n",
    "        However, if it is generated, the split is according to sample indexes\n",
    "        \"\"\"\n",
    "\n",
    "        split_by = {'sample_index': ['underage_costs', 'holding_costs', 'lead_times', 'initial_inventories', 'initial_warehouse_inventory'], \n",
    "                    'period': []}\n",
    "\n",
    "        if self.store_params['demand']['distribution'] == 'real':\n",
    "            split_by['period'].append('demands')\n",
    "        else:\n",
    "            split_by['sample_index'].append('demands')\n",
    "        if self.days_from_christmas is not None:\n",
    "            split_by['period'].append('days_from_christmas')\n",
    "        \n",
    "        return split_by\n",
    "    \n",
    "    def generate_demand_samples(self, problem_params, demand_params, seeds):\n",
    "        \"\"\"\n",
    "        Generate demand data\n",
    "        \"\"\"\n",
    "                \n",
    "        # sample parameters to generate demand if necessary (otherwise, does nothing)\n",
    "        self.generate_demand_parameters(problem_params, demand_params, seeds)\n",
    "\n",
    "        demand_generator_functions = {\"normal\": self.generate_normal_demand, 'poisson': self.generate_poisson_demand}\n",
    "\n",
    "        # sample demand\n",
    "        demand = demand_generator_functions[demand_params['distribution']](problem_params, demand_params, seeds['demand'])\n",
    "\n",
    "        if demand_params['clip']:\n",
    "            demand = np.clip(demand, 0, None)\n",
    "        \n",
    "        return torch.tensor(demand)\n",
    "\n",
    "    def generate_demand_parameters(self, problem_params, demand_params, seeds):\n",
    "        \"\"\"\n",
    "        Sample parameters of demand distribution, if necessary\n",
    "        \"\"\"\n",
    "        \n",
    "        if demand_params['sample_across_stores']:  # only supported for normal demand\n",
    "            demand_params.update(self.sample_normal_mean_and_std(problem_params, demand_params, seeds))\n",
    "    \n",
    "    def generate_normal_demand(self, problem_params, demand_params, seed):\n",
    "        \"\"\"\n",
    "        Generate normal demand data\n",
    "        \"\"\"\n",
    "\n",
    "        # set seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        if problem_params['n_stores'] == 1:\n",
    "            demand = np.random.normal(demand_params['mean'], \n",
    "                                      demand_params['std'], \n",
    "                                      size=(self.num_samples, 1, self.periods)\n",
    "                                      )\n",
    "        else:\n",
    "            # calculate covariance matrix and sample from multivariate normal\n",
    "            correlation = demand_params['correlation']\n",
    "            cov_matrix = [[correlation*v1*v2 if i!= j else v1*v2 \n",
    "                           for i, v1 in enumerate(demand_params['std'])\n",
    "                           ] \n",
    "                           for j, v2 in enumerate(demand_params['std'])\n",
    "                           ]\n",
    "            demand = np.random.multivariate_normal(demand_params['mean'], cov=cov_matrix, size=(self.num_samples, self.periods))\n",
    "            demand = np.transpose(demand, (0, 2, 1))\n",
    "\n",
    "        return demand\n",
    "\n",
    "    def generate_poisson_demand(self, problem_params, demand_params, seed):\n",
    "\n",
    "        # set seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        return np.random.poisson(demand_params['mean'], size=(self.num_samples, problem_params['n_stores'], self.periods))\n",
    "\n",
    "    def generate_data(self, demand_params, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate demand data\n",
    "        \"\"\"\n",
    "        demand_generator_functions = {\"normal\": self.generate_normal_demand_for_one_store}\n",
    "        demand = demand_generator_functions[demand_params['distribution']](demand_params, **kwargs)\n",
    "        \n",
    "        if demand_params['clip']:\n",
    "            demand = np.clip(demand, 0, None)\n",
    "\n",
    "        return torch.tensor(demand)\n",
    "        \n",
    "    def sample_normal_mean_and_std(self, problem_params, demand_params, seeds):\n",
    "        \"\"\"\n",
    "        Sample mean and std for normal demand\n",
    "        \"\"\"\n",
    "\n",
    "        # set seed\n",
    "        np.random.seed(seeds['mean'])\n",
    "\n",
    "        means = np.random.uniform(demand_params['mean_range'][0], demand_params['mean_range'][1], problem_params['n_stores'])\n",
    "        # del demand_params['mean_range']\n",
    "        np.random.seed(seeds['coef_of_var'])\n",
    "        coef_of_var = np.random.uniform(demand_params['coef_of_var_range'][0], demand_params['coef_of_var_range'][1], problem_params['n_stores'])\n",
    "        # del demand_params['coef_of_var_range']\n",
    "        stds = means * coef_of_var\n",
    "        return {'mean': means, 'std': stds}\n",
    "    \n",
    "    def generate_data_for_samples_and_stores(self, problem_params, cost_params, seed, discrete=False):\n",
    "        \"\"\"\n",
    "        Generate cost or lead time data, for each sample and store\n",
    "        \"\"\"\n",
    "        \n",
    "        # set seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        sample_functions = {False: np.random.uniform, True: np.random.randint}\n",
    "        # sample uniformly from the range (discrete)\n",
    "        this_sample_function = sample_functions[discrete]\n",
    "        \n",
    "        if cost_params['sample_across_stores'] == True:\n",
    "            return torch.tensor(this_sample_function(*cost_params['range'], problem_params['n_stores'])).expand(self.num_samples, -1)\n",
    "        elif cost_params['vary_across_samples']:\n",
    "\n",
    "            return torch.tensor(this_sample_function(*cost_params['range'], self.num_samples)).unsqueeze(1).expand(-1, problem_params['n_stores'])\n",
    "        elif cost_params['expand']:\n",
    "            return torch.tensor([cost_params['value']]).expand(self.num_samples, problem_params['n_stores'])\n",
    "        else:\n",
    "            return torch.tensor(cost_params['value'])\n",
    "    \n",
    "    def generate_initial_inventories(self, problem_params, store_params, demands, seed):\n",
    "        \"\"\"\n",
    "        Generate initial inventory data\n",
    "        \"\"\"\n",
    "        # set seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        if store_params['initial_inventory']['sample']:\n",
    "            # change type of demands to float\n",
    "\n",
    "            # demand_mean = demands.float().mean(dim=0)\n",
    "            demand_mean = demands.float().mean(dim=2).mean(dim=0)\n",
    "            demand_mults = np.random.uniform(*store_params['initial_inventory']['range_mult'], \n",
    "                                             size=(self.num_samples, \n",
    "                                                   problem_params['n_stores'], \n",
    "                                                   store_params['initial_inventory']['inventory_periods']\n",
    "                                                   )\n",
    "                                            )\n",
    "            return demand_mean[None, :, None] * demand_mults\n",
    "\n",
    "        else:\n",
    "            return torch.zeros(self.num_samples, \n",
    "                               problem_params['n_stores'], \n",
    "                               store_params['initial_inventory']['inventory_periods'])\n",
    "    \n",
    "    def generate_initial_warehouse_inventory(self, warehouse_params):\n",
    "        \"\"\"\n",
    "        Generate initial warehouse inventory data\n",
    "        \"\"\"\n",
    "\n",
    "        return torch.zeros(self.num_samples, \n",
    "                           1, \n",
    "                           warehouse_params['lead_time']\n",
    "                           )\n",
    "\n",
    "    def generate_days_from_christmas(self, store_params):\n",
    "\n",
    "        if store_params['demand']['distribution'] == 'real':\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_samples, data):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, num_samples, data):\n",
    "        self.data = data\n",
    "        self.num_samples = num_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCreator():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def create_datasets(self, scenario, split=True, by_period=False, by_sample_indexes=False, period_for_split=None, sample_index_for_split=None):\n",
    "\n",
    "        if split:\n",
    "            if by_period:\n",
    "                train_data, dev_data = self.split_by_period(scenario, period_for_split)\n",
    "            elif by_sample_indexes:\n",
    "                train_data, dev_data = self.split_by_sample_index(scenario, sample_index_for_split)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            return self.create_single_dataset(train_data), self.create_single_dataset(dev_data)\n",
    "        else:\n",
    "            return self.create_single_dataset(scenario.get_data())\n",
    "    \n",
    "    def split_by_sample_index(self, scenario, sample_index_for_split):\n",
    "        \"\"\"\n",
    "        Split dataset into dev and train sets by sample index\n",
    "        We consider the first entries to correspomd to the dev set (so that size of train set does not impact it)\n",
    "        This should be used when demand is synthetic (otherwise, if demand is real, there would be data leakage)\n",
    "        \"\"\"\n",
    "\n",
    "        data = scenario.get_data()\n",
    "\n",
    "        dev_data = {k: v[:sample_index_for_split] for k, v in data.items()}\n",
    "        train_data = {k: v[sample_index_for_split:] for k, v in data.items()}\n",
    "\n",
    "        return train_data, dev_data\n",
    "    \n",
    "    def create_single_dataset(self, data):\n",
    "        \"\"\"\n",
    "        Create a single dataset\n",
    "        \"\"\"\n",
    "\n",
    "        num_samples = len(data['initial_inventories'])\n",
    "\n",
    "        return MyDataset(num_samples, data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only execute if name is main\n",
    "if __name__ == '__main__':\n",
    "    # test the class\n",
    "    seeds = {\"underage_cost\": 28, \"holding_cost\": 73, \"mean\": 33, \"coef_of_var\": 92, \"lead_time\": 41, 'demand': 57, \"initial_inventory\": 88}\n",
    "    # \"seeds\": {\"underage\": 28, \"holding\": 73, \"mean\": 33, \"stds\": 92, \"demand_sequence\": 57, \"w_lead_time\": 88, \"perturbation\": 84, \"store_lead_times\": 41}\n",
    "    problem_params = {'n_stores': 10, 'periods': 50}\n",
    "    num_samples = 512\n",
    "    batch_size = 128\n",
    "    store_params = {'demand': {'sample_across_stores': True,\n",
    "                               'mean_range': [2.5, 7.5], \n",
    "                               'coef_of_var_range': [0.16, 0.32],\n",
    "                               'distribution': 'normal',\n",
    "                               'correlation': 0.5,\n",
    "                               'clip': True\n",
    "                               },\n",
    "                    \n",
    "                  #   'demand_1': {'sample_across_stores': False,\n",
    "                  #              'mean': [5.0], \n",
    "                  #              'distribution': 'poisson',\n",
    "                  #              'clip': True\n",
    "                  #              },\n",
    "\n",
    "                    'lead_time': {'sample_across_stores': True,\n",
    "                                   'vary_across_samples': False, \n",
    "                                   'range': [4, 7]\n",
    "                                #    'value': 4\n",
    "                                   },\n",
    "\n",
    "                    'holding_cost': {'sample_across_stores': False, \n",
    "                                      'vary_across_samples': False,\n",
    "                                      'expand': True,\n",
    "                                      'value': 1\n",
    "                                      },\n",
    "\n",
    "                    'underage_cost': {'sample_across_stores': True,\n",
    "                                       'vary_across_samples': False, \n",
    "                                       'expand': False, \n",
    "                                       # 'value': 5.0,\n",
    "                                       'range': [2.5, 7.5],\n",
    "                                       },\n",
    "\n",
    "                     'initial_inventory': {'sample': True,\n",
    "                                           'range_mult': [0, 1],\n",
    "                                           'inventory_periods': 6\n",
    "                                           }\n",
    "                    }\n",
    "    \n",
    "    warehouse_params = {'holding_cost': 0.3, \n",
    "                        'lead_time': 4}\n",
    "    \n",
    "    scenario = Scenario(problem_params, store_params, warehouse_params, num_samples, seeds)\n",
    "    creator = DatasetCreator()\n",
    "    train_dataset, dev_dataset = creator.create_datasets(scenario, split=True, by_sample_indexes=True, sample_index_for_split=400)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    creator = DatasetCreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_dataset, dev_dataset = creator.create_datasets(scenario, split=True, by_sample_indexes=True, sample_index_for_split=400)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatiasRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
